{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Optional\n",
    "import pandas as pd \n",
    "from copy import deepcopy\n",
    "from scipy.stats.contingency import odds_ratio\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import itertools\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFILE = '/home/grace/work/SEER/data/SEER_2010_2020.clean.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = pd.read_csv(INFILE, header=0, sep='\\t', na_values='.')\n",
    "master = master.loc[master['diagnosis_year'] >= 2010]\n",
    "master.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weird_pids = master[master['site'] != master['primary_site']]['patient_id']\n",
    "weird_pids = set(weird_pids.to_list())\n",
    "\n",
    "mismatch_df = master[master['patient_id'].isin(weird_pids)]\n",
    "# print(mismatch_df.shape)\n",
    "# print(mismatch_df.head())\n",
    "singles_df = mismatch_df.drop_duplicates(subset=['patient_id'], keep=False)\n",
    "multiples_df = mismatch_df[mismatch_df.duplicated(subset=['patient_id'], keep=False)]\n",
    "# print(singles_df.shape)\n",
    "# print(singles_df.head())\n",
    "\n",
    "# only interested in pure mismatches\n",
    "combinations = pd.DataFrame()\n",
    "combinations['site'] = singles_df['site']\n",
    "combinations['site_category'] = singles_df['site_category']\n",
    "combinations['primary_site'] = singles_df['primary_site']\n",
    "combinations['site|primary_site'] = combinations['site'] + '|' + combinations['primary_site']\n",
    "combinations['site_category|primary_site'] = combinations['site_category'] + '|' + combinations['primary_site']\n",
    "# print(combinations['site|primary_site'].value_counts().head(10))\n",
    "print(combinations['site_category|primary_site'].value_counts().head(20))\n",
    "\n",
    "\"\"\"\n",
    "site_category|primary_site\n",
    "Non-Hodgkin Lymphoma|Nodal (MSM) | Miscellaneous     97818\n",
    "Miscellaneous|Leukemia                               71056\n",
    "Myeloma|Leukemia                                     57624\n",
    "Hodgkin Lymphoma|Nodal (MSM) | Miscellaneous         21241\n",
    "Mouth|Tonsil | Nodal (MSM)                           15602\n",
    "Non-Hodgkin Lymphoma|Skin                            11665\n",
    "Non-Hodgkin Lymphoma|Leukemia                         7308\n",
    "Mesothelioma|Pleura                                   6144\n",
    "\"\"\"\n",
    "\n",
    "# print(multiples_df.shape)\n",
    "# print(multiples_df.head())\n",
    "\n",
    "# common mismatches\n",
    "# Myeloma | Leukemia "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "TSTAGE_PATTERN = r'^(T[1234])'\n",
    "NSTAGE_PATTERN = r'^(N[0123])'\n",
    "GSTAGE_PATTERN = r'^(IV|III|II|I|0)'\n",
    "\n",
    "def std_tstage(stage: str | float) -> str | float:\n",
    "    \"\"\"\n",
    "    target: {T1, T2, T3, T4}\n",
    "    T1a -> T1 etc\n",
    "    ignore T0, TX, Ta, Tis, Tispd etc. \n",
    "    \"\"\"\n",
    "    if isinstance(stage, str):\n",
    "        m = re.match(TSTAGE_PATTERN, stage)\n",
    "        if m:\n",
    "            return m.group(1)\n",
    "    return np.nan\n",
    "\n",
    "def std_nstage(stage: str | float) -> str | float:\n",
    "    \"\"\"\n",
    "    target: {N0, N1, N2, N3}\n",
    "    ignore NX\n",
    "    N0: no detectable lymph nodes (ie no spread)\n",
    "    \"\"\"\n",
    "    if isinstance(stage, str):\n",
    "        m = re.match(NSTAGE_PATTERN, stage)\n",
    "        if m:\n",
    "            return m.group(1)\n",
    "    return np.nan\n",
    "\n",
    "def std_gstage(stage: str | float) -> str | float:\n",
    "    \"\"\"\n",
    "    target: {N0, N1, N2, N3}\n",
    "    ignore NX\n",
    "    N0: no detectable lymph nodes (ie no spread)\n",
    "    \"\"\"\n",
    "    if isinstance(stage, str):\n",
    "        if stage == 'OCCULT':\n",
    "            return np.nan\n",
    "        m = re.match(GSTAGE_PATTERN, stage)\n",
    "        assert m \n",
    "        return m.group(1)\n",
    "    return np.nan\n",
    "\n",
    "master['TSTAGE_STD'] = master['t_stage_ajcc'].apply(std_tstage)\n",
    "master['NSTAGE_STD'] = master['n_stage_ajcc'].apply(std_nstage)\n",
    "master['GSTAGE_STD'] = master['g_stage_ajcc'].apply(std_gstage)\n",
    "master['brain_met'] = master['brain_met'].apply(lambda x: 'YES' if x else 'NO')\n",
    "master = master.rename(columns={'grade': 'GRADE', 'hist_cateogry': 'HISTOLOGY', 'brain_met': 'BRAIN_MET', 'site_category': 'SITE'})\n",
    "master.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "\n",
    "## Record-Level Analysis \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO improve\n",
    "records_df = master.drop_duplicates(subset=['patient_id'], keep='last')\n",
    "print(records_df.shape)\n",
    "records_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_df['SITE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutual information \n",
    "from sklearn.metrics import mutual_info_score, normalized_mutual_info_score, ConfusionMatrixDisplay\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.model_selection import cross_validate\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style='white', context='notebook', rc={'figure.figsize':(14,10)})\n",
    "\n",
    "from bokeh.plotting import figure, show, output_notebook, output_file\n",
    "from bokeh.models import HoverTool, ColumnDataSource, CategoricalColorMapper, LinearColorMapper\n",
    "from bokeh.palettes import Spectral10\n",
    "output_notebook()\n",
    "\n",
    "def confusion_matrix(df: pd.DataFrame, col1: str, col2: str):\n",
    "    return df.groupby([col1, col2]).size().unstack(fill_value=0)\n",
    "\n",
    "def do_mutual_information(df: pd.DataFrame, cat1: str, cat2: str) -> float:\n",
    "    temp = df[[cat1, cat2]]\n",
    "    temp = temp.dropna()\n",
    "    c_matrix = confusion_matrix(temp, cat2, cat1)\n",
    "    mi3 = normalized_mutual_info_score(labels_pred=temp[cat1], labels_true=temp[cat2])\n",
    "    return float(mi3)\n",
    "\n",
    "def do_pca(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.dropna()\n",
    "    df = df.reset_index(drop=True)\n",
    "    bm_series = df['BRAIN_MET']\n",
    "    df = df.drop('BRAIN_MET', axis=1)\n",
    "    # print(df.shape)\n",
    "    # print(df.head())\n",
    "    reducer = PCA(n_components=2)\n",
    "    embedding = reducer.fit_transform(df.to_numpy())\n",
    "    embedding_df = pd.DataFrame(embedding, columns=('x', 'y'))\n",
    "    embedding_df.index = df.index\n",
    "    embedding_df = pd.merge(df, embedding_df, left_index=True, right_index=True)\n",
    "    embedding_df['BRAIN_MET'] = bm_series\n",
    "    return embedding_df\n",
    "\n",
    "def plot_interactive(df: pd.DataFrame, title: str, color_by: str='BRAIN_MET'):\n",
    "    assert color_by in df.columns\n",
    "    \n",
    "    # categorical\n",
    "    if color_by in df.columns:\n",
    "        if color_by == 'BRAIN_MET':\n",
    "            palette = ('#e6194b', '#3cb44b')\n",
    "        # if color_by == 'primary':\n",
    "        #     palette = ('#e6194b', '#3cb44b', '#ffe119', '#4363d8', '#f58231', '#911eb4', '#46f0f0', '#f032e6', '#bcf60c', '#fabebe', '#008080', '#e6beff', '#9a6324', '#fffac8', '#800000', '#aaffc3', '#808000')\n",
    "        # elif color_by == 'common':\n",
    "        #     palette = ('#e6194b', '#3cb44b')\n",
    "        # elif color_by == 'gender':\n",
    "        #     palette = ('#e6194b', '#3cb44b')\n",
    "        # elif color_by == 'batch':\n",
    "        #     palette = ('#ffe119', '#4363d8', '#f58231')\n",
    "        # elif color_by == 'hlfa':\n",
    "        #     palette = ('#e6194b', '#3cb44b')\n",
    "        the_mapper = CategoricalColorMapper(factors=df[color_by].unique(), palette=palette)\n",
    "\n",
    "    # # continuous\n",
    "    # elif color_by in ['age','purity','ploidy','loh','pga']:\n",
    "    #     the_mapper = LinearColorMapper(palette='Magma256',low=df[color_by].min(),high=df[color_by].max())\n",
    "    # else:\n",
    "    #     raise ValueError(\"Invalid color_by value\")\n",
    "\n",
    "    plot_figure = figure(\n",
    "        title=title,\n",
    "        width=1000,\n",
    "        height=600,\n",
    "        tools=('pan, wheel_zoom, reset')\n",
    "    )\n",
    "\n",
    "    attributes = [x for x in df.columns if x not in ['x', 'y']]\n",
    "    templ = \"\"\"\n",
    "    <div>\n",
    "    \"\"\"\n",
    "    for att in attributes:\n",
    "        templ += f\"\"\"\n",
    "        <div>\n",
    "            <span style='font-size: 16px; color: #224499'>{att}:</span>\n",
    "            <span style='font-size: 16px'>@{att}</span>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    templ += \"\"\"\n",
    "    <div>\n",
    "    \"\"\"\n",
    "    \n",
    "    plot_figure.add_tools(HoverTool(tooltips=templ))\n",
    "\n",
    "    datasource = ColumnDataSource(df)\n",
    "    plot_figure.circle(\n",
    "        'x',\n",
    "        'y',\n",
    "        source=datasource,\n",
    "        color=dict(field=color_by, transform=the_mapper),\n",
    "        line_alpha=0.6,\n",
    "        fill_alpha=0.6,\n",
    "        size=8,\n",
    "        legend_label=color_by\n",
    "    )\n",
    "    show(plot_figure)\n",
    "\n",
    "def do_decision_tree(df: pd.DataFrame, title: str, target: str) -> None:\n",
    "    df = df.dropna()\n",
    "    min_samples_leaf = max(df.shape[0]//100, 1)\n",
    "    df.head()\n",
    "    X = df.drop(target, axis=1)\n",
    "    Y = df[target]\n",
    "    clf = DecisionTreeClassifier(max_leaf_nodes=12, max_depth=5, min_samples_leaf=min_samples_leaf)\n",
    "    clf = clf.fit(X, Y)\n",
    "    \n",
    "    fig = plt.figure(figsize=(40, 40))\n",
    "    _ = plot_tree(clf, feature_names=X.columns.to_list(), filled=True, proportion=False)\n",
    "    plt.title(title)\n",
    "\n",
    "    clf = DecisionTreeClassifier(max_leaf_nodes=12)\n",
    "    scores = cross_validate(clf, X, Y, cv=3, scoring=('recall', 'precision', 'accuracy', 'f1'))\n",
    "\n",
    "    print('\\nMETRICS ---')\n",
    "    for k, v in scores.items():\n",
    "        print(f'{k}: {np.mean(v):0.3f}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "SITES = ['Lung and Bronchus', 'Esophagus', 'Skin', 'Breast', 'Prostate']\n",
    "# SITES = ['Breast']\n",
    "# FEATURES = ['TSTAGE_STD', 'NSTAGE_STD', 'GSTAGE_STD', 'GRADE', 'HISTOLOGY', 'BRAIN_MET']\n",
    "# FEATURES = ['TSTAGE_STD', 'NSTAGE_STD', 'GSTAGE_STD', 'GRADE', 'BRAIN_MET']\n",
    "# FEATURES = ['TSTAGE_STD', 'NSTAGE_STD', 'GSTAGE_STD', 'GRADE', 'HISTOLOGY', 'BRAIN_MET']\n",
    "FEATURES = ['TSTAGE_STD', 'NSTAGE_STD', 'GRADE', 'HISTOLOGY', 'BRAIN_MET']\n",
    "TARGET = 'BRAIN_MET'\n",
    "\n",
    "DO_MI = False\n",
    "DO_PCA = False\n",
    "DO_DC = True\n",
    "\n",
    "mi_df = pd.DataFrame(index=SITES, columns=FEATURES)\n",
    "\n",
    "for site in SITES:\n",
    "    print(f'\\n\\n --- {site} --- ')\n",
    "    df = records_df.loc[records_df['SITE']==site]\n",
    "    df = df[FEATURES]\n",
    "    \n",
    "    # Mutual Information\n",
    "    if DO_MI:\n",
    "        for feature in FEATURES:\n",
    "            mi_stat = do_mutual_information(df, feature, TARGET)\n",
    "            mi_df.loc[site, feature] = mi_stat\n",
    "    \n",
    "    # PCA \n",
    "    if DO_PCA or DO_DC:\n",
    "        if 'TSTAGE_STD' in FEATURES:\n",
    "            df['TSTAGE_STD'] = df['TSTAGE_STD'].map({'T1': 1, 'T2': 2, 'T3': 3, 'T4': 4})\n",
    "        if 'NSTAGE_STD' in FEATURES:\n",
    "            df['NSTAGE_STD'] = df['NSTAGE_STD'].map({'N0': 0, 'N1': 1, 'N2': 2, 'N3': 3})\n",
    "        if 'GSTAGE_STD' in FEATURES:\n",
    "            df['GSTAGE_STD'] = df['GSTAGE_STD'].map({'I': 1, 'II': 2, 'III': 3, 'IV': 4})\n",
    "        if 'GRADE' in FEATURES:\n",
    "            df['GRADE'] = df['GRADE'].map({'G1': 1, 'G2': 2, 'G3': 3, 'G4': 4})\n",
    "    \n",
    "    # PCA \n",
    "    if DO_PCA:\n",
    "        if 'HISTOLOGY' in FEATURES:\n",
    "            le = LabelEncoder()\n",
    "            df['HISTOLOGY'] = le.fit_transform(df['HISTOLOGY'])\n",
    "        # print(df.head())\n",
    "        embedding_df = do_pca(df)\n",
    "        # print(embedding_df.head())\n",
    "        plot_interactive(embedding_df, title=site, color_by='BRAIN_MET')\n",
    "        df['HISTOLOGY'] = le.inverse_transform(df['HISTOLOGY'])\n",
    "\n",
    "    # Decision Tree\n",
    "    if DO_DC:\n",
    "        # balancing classes\n",
    "        yes_data = df.loc[df[TARGET] == 'YES']\n",
    "        no_data = df.loc[df[TARGET] == 'NO'].head(yes_data.shape[0])\n",
    "        df = pd.concat([yes_data, no_data], ignore_index=True)\n",
    "\n",
    "        # category encoding\n",
    "        print(f'Decision tree using {df.shape[0]} records (balanced classes).')\n",
    "        if 'HISTOLOGY' in FEATURES:\n",
    "            start_rows = df.shape[0]\n",
    "            df = df.reset_index(drop=True)\n",
    "            lb = LabelBinarizer()\n",
    "            histology_df = pd.DataFrame(data=lb.fit_transform(df['HISTOLOGY']), columns=['HIST_'+ x for x in lb.classes_]) # type: ignore\n",
    "            df = df.drop('HISTOLOGY', axis=1)\n",
    "            df = pd.concat([df, histology_df], axis=1)\n",
    "            end_rows = df.shape[0]\n",
    "            assert start_rows == end_rows\n",
    "        df[TARGET] = df[TARGET].map({'YES': 1, 'NO': 0})\n",
    "        do_decision_tree(df, title=site, target=TARGET)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "\n",
    "def plot_matrix(df: pd.DataFrame) -> None:\n",
    "    plt.matshow(df) # imshow\n",
    "    #plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(df.columns))\n",
    "    plt.xticks(tick_marks, df.columns, rotation=45)\n",
    "    plt.yticks(tick_marks, df.index)\n",
    "    #plt.tight_layout()\n",
    "    plt.ylabel(df.index.name)\n",
    "    plt.xlabel(df.columns.name)\n",
    "\n",
    "mi_df = mi_df.apply(pd.to_numeric)\n",
    "mi_norm_df = mi_df.apply(lambda x: x/x.max(), axis=1)\n",
    "# print(mi_df)\n",
    "# print(mi_norm_df)\n",
    "\n",
    "plot_matrix(mi_df)\n",
    "plot_matrix(mi_norm_df)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# X_test = X.head(1).to_numpy()\n",
    "# feature = clf.tree_.feature\n",
    "# threshold = clf.tree_.threshold\n",
    "\n",
    "# node_indicator = clf.decision_path(X_test)\n",
    "# leaf_id = clf.apply(X_test)\n",
    "\n",
    "# sample_id = 0\n",
    "# # obtain ids of the nodes `sample_id` goes through, i.e., row `sample_id`\n",
    "# node_index = node_indicator.indices[\n",
    "#     node_indicator.indptr[sample_id] : node_indicator.indptr[sample_id + 1]\n",
    "# ]\n",
    "\n",
    "# print(\"Rules used to predict sample {id}:\\n\".format(id=sample_id))\n",
    "# for node_id in node_index:\n",
    "#     # continue to the next node if it is a leaf node\n",
    "#     if leaf_id[sample_id] == node_id:\n",
    "#         continue\n",
    "\n",
    "#     # check if value of the split feature for sample 0 is below threshold\n",
    "#     if X_test[sample_id, feature[node_id]] <= threshold[node_id]:\n",
    "#         threshold_sign = \"<=\"\n",
    "#     else:\n",
    "#         threshold_sign = \">\"\n",
    "\n",
    "#     print(\n",
    "#         \"decision node {node} : (X_test[{sample}, {feature}] = {value}) \"\n",
    "#         \"{inequality} {threshold})\".format(\n",
    "#             node=node_id,\n",
    "#             sample=sample_id,\n",
    "#             feature=feature[node_id],\n",
    "#             value=X_test[sample_id, feature[node_id]],\n",
    "#             inequality=threshold_sign,\n",
    "#             threshold=threshold[node_id],\n",
    "#         )\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "# data = df.head(10000)\n",
    "df = df[['site', 'TSTAGE_STD', 'NSTAGE_STD', 'GSTAGE_STD', 'grade', 'brain_met']]\n",
    "df = df[['site', 'TSTAGE_STD', 'NSTAGE_STD', 'GSTAGE_STD', 'grade', 'brain_met']]\n",
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)\n",
    "print(f'Using {df.shape[0]} records.')\n",
    "lb = LabelBinarizer()\n",
    "tstage_df = pd.DataFrame(data=lb.fit_transform(df['TSTAGE_STD']), columns=lb.classes_) # type: ignore\n",
    "site_df = pd.DataFrame(data=lb.fit_transform(df['site']), columns=lb.classes_) # type: ignore\n",
    "full_df = pd.concat([tstage_df, site_df, df['brain_met']], axis=1)\n",
    "\n",
    "X = full_df.drop('brain_met', axis=1)\n",
    "Y = full_df['brain_met']\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X, Y)\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "fig = plt.figure(figsize=(40, 40))\n",
    "_ = plot_tree(clf, feature_names=X.columns.to_list(), filled=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "\n",
    "## Patient-Level Analysis \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "\n",
    "#### Prevalence\n",
    "\n",
    "The proportion of all people in the study population who have the outcome of interest (e.g., disease or condition) at a particular time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_RECORDS_PER_SITE = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# Records per site #\n",
    "####################\n",
    "\n",
    "# simple value counts (ie num records per site)\n",
    "df = deepcopy(master)\n",
    "total_df = df['SITE'].value_counts()\n",
    "total_df = total_df.reset_index()\n",
    "total_df.columns = ['SITE', 'count']\n",
    "total_df = total_df.sort_values(by=['count'], ascending=False)\n",
    "\n",
    "# filtering & defining common sort order\n",
    "total_df = total_df.loc[total_df['count'] > MIN_RECORDS_PER_SITE]  # filter low count sites \n",
    "\n",
    "# to ensure proper order and colors for following plots\n",
    "site_map = {site: idx + 1 for idx, site in zip(total_df.index, total_df['SITE'])}\n",
    "site_map['Total'] = 0\n",
    "all_sites = set(total_df['SITE'].to_list())\n",
    "common_cmap = {site: col for site, col in zip(all_sites, itertools.cycle(sns.color_palette('muted', as_cmap=True)))}\n",
    "\n",
    "#############################\n",
    "# BM prevalence (2010-2020) #\n",
    "#############################\n",
    "\n",
    "# total prevalence (ie num records marked as possessing BrainMet)\n",
    "data = []\n",
    "bm_count = df['BRAIN_MET'].value_counts()['YES']\n",
    "print(f'Total prevalence: {(bm_count/df.shape[0]) * 100:0.1f} in 100 people')\n",
    "data.append(['Total', bm_count, bm_count/df.shape[0]])\n",
    "\n",
    "# site prevalence (as above, but per site. last site only)\n",
    "df = df[['SITE', 'BRAIN_MET']]\n",
    "counts = df.groupby('SITE').value_counts(sort=True, ascending=False)\n",
    "for site in all_sites:\n",
    "    has_bm = 0 if 'YES' not in counts[site] else counts[site]['YES']\n",
    "    no_bm = 0 if 'NO' not in counts[site] else counts[site]['NO']\n",
    "    data.append([site, has_bm, has_bm/(has_bm+no_bm)])\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prev_df = pd.DataFrame(columns=['SITE', 'count', 'prevalence'], data=data)\n",
    "print(sorted(prev_df['SITE'].to_list()))\n",
    "print(sorted(list(site_map.keys())))\n",
    "assert set(prev_df['SITE'].to_list()) == set(list(site_map.keys()))\n",
    "# # sorting\n",
    "# get_pos = lambda x: site_map[x]\n",
    "# prev_df['position'] = prev_df['site'].apply(get_pos)\n",
    "# prev_df = prev_df.sort_values(by='position', ascending=True)    \n",
    "# display as percent\n",
    "prev_df['prevalence'] = prev_df['prevalence'] * 100                     \n",
    "\n",
    "# plot total counts\n",
    "plt.figure(figsize=(12, 4), dpi=100)\n",
    "plt.title('Records per site (counts)')\n",
    "plt.xticks(rotation=90)\n",
    "sns.barplot(total_df, x='SITE', y='count', palette=common_cmap, log=True)\n",
    "\n",
    "# plot BM counts\n",
    "prev_df = prev_df.sort_values(by='count', ascending=False)  \n",
    "plt.figure(figsize=(12, 4), dpi=100)\n",
    "another_cmap = deepcopy(common_cmap)\n",
    "another_cmap['Total'] = '#FF0000'\n",
    "plt.title('BrainMet cases per site (counts)')\n",
    "plt.xticks(rotation=90)\n",
    "sns.barplot(prev_df, x='SITE', y='count', palette=another_cmap, log=True)\n",
    "\n",
    "# plot BM prevalence\n",
    "prev_df = prev_df.sort_values(by='prevalence', ascending=False)  \n",
    "plt.figure(figsize=(12, 4), dpi=100)\n",
    "plt.title('BrainMet prevalence per site (percentage %)')\n",
    "plt.xticks(rotation=90)\n",
    "sns.barplot(prev_df, x='SITE', y='prevalence', palette=another_cmap, log=True)\n",
    "\n",
    "# note prostate, breast, esophagus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "\n",
    "#### Odds\n",
    "\n",
    "A single point in time.\n",
    "\n",
    "**Odds** <br>\n",
    "The probability that an event occurs divided by the probability that the event does not occur.\n",
    "\n",
    "**Odds ratio**<br>\n",
    "Ratio ie proportional odds. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grade\n",
    "df = deepcopy(master)\n",
    "df = df[['SITE', 'GRADE', 'BRAIN_MET']]\n",
    "grade_df = df[['GRADE', 'BRAIN_MET']]\n",
    "# grade_df['last_grade'] = grade_df['grades'].apply(get_last)\n",
    "# grade_df = grade_df[[\"last_grade\", \"bm_status\"]]\n",
    "grade_df = grade_df.groupby(\"GRADE\").value_counts()\n",
    "\n",
    "print(grade_df)\n",
    "props = pd.DataFrame(columns=['grade', 'proportion'])\n",
    "for cat in ['G1', 'G2', 'G3', 'G4']:\n",
    "    cat_prop = grade_df[cat]['YES']/(grade_df[cat]['YES']+grade_df[cat]['NO']) * 100\n",
    "    props.loc[cat] = pd.Series({'grade': cat, 'proportion': cat_prop})\n",
    "sns.barplot(props, x=\"grade\", y=\"proportion\", palette='muted')\n",
    "print(props)\n",
    "\n",
    "# SITES = ['Lung and Bronchus', 'Esophagus', 'Skin', 'Breast', 'Prostate']\n",
    "SITES = ['Lung and Bronchus', 'Esophagus', 'Breast', 'Prostate']\n",
    "for site in SITES:\n",
    "    grade_df = df.loc[df['SITE']==site]\n",
    "    grade_df = grade_df[['GRADE', 'BRAIN_MET']]\n",
    "    # grade_df['last_grade'] = grade_df['grades'].apply(get_last)\n",
    "    # grade_df = grade_df[[\"last_grade\", \"bm_status\"]]\n",
    "    grade_df = grade_df.groupby(\"GRADE\").value_counts()\n",
    "    print(grade_df)\n",
    "\n",
    "    print()\n",
    "    print(site)\n",
    "    print(grade_df)\n",
    "    props = pd.DataFrame(columns=['grade', 'proportion'])\n",
    "    \n",
    "    for cat in ['G1', 'G2', 'G3', 'G4']:\n",
    "        cat_prop = grade_df[cat]['YES']/(grade_df[cat]['YES']+grade_df[cat]['NO']) * 100\n",
    "        props.loc[cat] = pd.Series({'grade': cat, 'proportion': cat_prop})\n",
    "    plt.figure(figsize=(5, 5), dpi=100)\n",
    "    sns.barplot(props, x=\"grade\", y=\"proportion\", palette='muted')\n",
    "    print(props)\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios = []\n",
    "pairs = [\n",
    "    ('G2', 'G1'),\n",
    "    ('G3', 'G2'),\n",
    "    ('G4', 'G3'),\n",
    "]\n",
    "for change, reference in pairs:\n",
    "    print(f'\\n{change} vs {reference}')\n",
    "    cont = pd.DataFrame(columns=[change, reference], index=['YES', 'NO'], data=[[0, 0],[0, 0]])\n",
    "    cont.loc['YES', reference] = grade_df[reference]['YES']\n",
    "    cont.loc['YES', change] = grade_df[change]['YES']\n",
    "    cont.loc['NO', reference] = grade_df[reference]['NO']\n",
    "    cont.loc['NO', change] = grade_df[change]['NO']\n",
    "    print(cont)\n",
    "    print()\n",
    "    res = odds_ratio(cont)\n",
    "    ci = res.confidence_interval(confidence_level=0.95)\n",
    "    print(f'odds ratio: {res.statistic:0.2f}')\n",
    "    print(f'p-value: [{ci.low:0.2f}, {ci.high:0.2f}]')\n",
    "    ratios.append((f'{reference}->{change}', res.statistic, ci.low, ci.high))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(3, 3), dpi=150)\n",
    "yvals = [r[0] for r in ratios]\n",
    "xvals = [r[1] for r in ratios]\n",
    "xerrs = [[r[1] - r[2] for r in ratios], [r[3] - r[1] for r in ratios]]\n",
    "plt.errorbar(y=yvals, x=xvals, xerr=xerrs,\n",
    "            color='black',  capsize=3, linestyle='None', linewidth=1,\n",
    "            marker=\"o\", markersize=5, mfc=\"black\", mec=\"black\")\n",
    "plt.axvline(x=1, linewidth=0.8, linestyle='--', color='black')\n",
    "plt.tick_params(axis='both', which='major', labelsize=8)\n",
    "plt.xlabel('Odds Ratio and 95% Confidence Interval', fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# OR(common vs uncommon)\n",
    "# OR(common G1 vs uncommon G1)\n",
    "# OR(common G2 vs uncommon G2)\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-stage\n",
    "df = deepcopy(master)\n",
    "df['last_t_stage'] = df['t_stages'].apply(get_last)\n",
    "\n",
    "# TODO ask Chris about this\n",
    "temp = df.loc[df['t_stages'] != df['last_t_stage']]\n",
    "temp[['t_stages', 'last_t_stage']]\n",
    "# print(f'Total records: {df.shape[0]}')\n",
    "# print(f'Multiple tumors records: {temp.shape[0]}')\n",
    "# print(f'Prevalence: {(temp.shape[0]/df.shape[0])*100}')\n",
    "\n",
    "# TODO ask Chris about this\n",
    "df[[\"last_t_stage\", \"bm_status\"]].groupby(\"last_t_stage\").value_counts()\n",
    "\n",
    "# TODO mapping\n",
    "# target: {T1, T2, T3, T4}\n",
    "# - ignore T0\n",
    "# - ignore Ta, Tis, Tispd etc. \n",
    "# - T1a -> T1\n",
    "df.loc[df['bm_status'] == 'YES'][['last_t_stage']].value_counts(sort=True, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "\n",
    "#### Incidence\n",
    "\n",
    "The proportion of at-risk subjects who develop the outcome of interest.\n",
    "\n",
    "The number of new cases over a time period divided by the total person-time at risk during that time period.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incidence\n",
    "# total incidence (2010-2020)\n",
    "# add field for person-time\n",
    "from copy import deepcopy\n",
    "df = deepcopy(master[master['timepoint_first'] != master['timepoint_last']])\n",
    "\n",
    "# subset by 'at risk'\n",
    "df = df.loc[df['bm_existing'] == 'NO']\n",
    "\n",
    "# subset by time period\n",
    "df['tp1'] = df['timepoint_first']\n",
    "df['tp2'] = df[[\"timepoint_last\", \"death_year\"]].max(axis=1)\n",
    "df = df.loc[df['tp2'] < 2021]\n",
    "df['person_years'] = df['tp2'] - df['tp1']\n",
    "df[['tp1', 'tp2', 'person_years']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def do_mutual_information(df: pd.DataFrame, cat1: str, cat2: str, top: Optional[int]=None, should_print: bool=False) -> None:\n",
    "    print(f'{cat1} vs {cat2} ---\\n')\n",
    "    temp = df[[cat1, cat2]]\n",
    "    temp = temp.dropna()\n",
    "    # temp = temp.reset_index(drop=True)\n",
    "    if top is not None:\n",
    "        temp = temp.head(top)\n",
    "    print(f'Using {temp.shape[0]} records.')\n",
    "    if should_print:\n",
    "        print(temp.head(10))\n",
    "        print()\n",
    "    # c_matrix = confusion_matrix(temp, cat2, cat1)\n",
    "    # print(c_matrix)\n",
    "    # print()\n",
    "\n",
    "    # mi1 = mutual_info_score(labels_pred=temp[cat1], labels_true=temp[cat2])\n",
    "    # mi2 = mutual_info_score(labels_true=None, labels_pred=None, contingency=c_matrix)\n",
    "    mi3 = normalized_mutual_info_score(labels_pred=temp[cat1], labels_true=temp[cat2])\n",
    "    \n",
    "    # print(f'Mutual information Arrays: {mi1:0.3f}')\n",
    "    # print(f'Mutual information Confusion: {mi2:0.3f}')\n",
    "    print(f'Mutual information Normalized: {mi3:0.3f}\\n\\n')\n",
    "    \n",
    "    # plt.figure(figsize=(5, 5), dpi=100)\n",
    "    # prev_df = pd.DataFrame(columns=c_matrix.columns, index=c_matrix.index)\n",
    "    # for field in c_matrix.columns:\n",
    "    #     c_matrix[field] = (c_matrix[field] / c_matrix[field].sum())\n",
    "    # print(c_matrix)\n",
    "    # c_matrix = c_matrix.sort_index(ascending=False)\n",
    "    # sns.barplot(c_matrix.T['YES'])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
